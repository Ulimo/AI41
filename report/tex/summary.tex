\section{Summary}
This work has been about implementing and testing a word predictor in the purpose of finding out what makes it effective. Effectiveness was defined as minimizing the number of key-strokes necessary to complete a given sentence. This resulted in an implementation which used common techniques for improving performance. KYLM and Open NLP that were used to generate N-gram probabilities and POS-tagging respectively, were the foundational stones for this work. On top of that, development of grammar constraints and context recognition was made as means of conducting experiments to see what could make a word predictor more effective. The tests in this project concluded that grammar constrains didnâ€™t seem to benefit the effectiveness of the word predictor while context recognition proved to do so, given that the corpus contains usable N-grams.  
\section{Contribution}
We, the members of group 41, unanimously declare that we have all equally contributed toward the completion of this project.
