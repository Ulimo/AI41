\section{Introduction}
Word predictors have traditionally been used to increase the communication ability of persons with speech and language impairments\cite{Lesher99effectsof}\cite{keystrokes}\cite{corpus}. More recently, they have also come to use in increasing efficiency of typing in general \cite{Lesher99effectsof}, such as in-line search suggestions in search engines and the \emph{prediction window} for touch screen keyboards. 

\paragraph{Problem statement}
Presenting word suggestions to a user requires a statistical language model\cite{keystrokes} to calculate the probablilty $P(word|history)$, the most common being N-gram models\cite{Wandmacher}. The problem and the goal of this work is to find what makes such a word predictor effective. In this work, by effective, it is meant that a more effective word predictor requires a lower KSR (key stroke rate) than a less effective one. More specifically, the goal is to test different functionalities that are thought to increase the effectiveness of a word predictor and evaluate the results. The problem is worth addressing because the solution could help making communication with machines more effective in general. Word prediction could also be used as an important component in other areas of NLP, such as speech recognition, why their effectiveness is a cruical part in NLP.

\paragraph{Hypotheses}
Three different functionalities that were thought to affect the effectiveness were implemented and evaluated in this work. These were probability smoothing, grammar constraints and context recognition (sometimes called topic modeling).
Word prediction is an important part in Natural Language Processing (NLP) since in many tasks it is necessary to determine the next word  \cite{DBLP:journals/corr/cs-CL-0009027}.  Predicting words correctly can be a difficult task since there are a lot of factors that have to be taken into account. Grammar constraints and context of the input are often complex matters which need to be analyzed in order to make accurate predictions.
 
Gregory W. Lesher et.al \cite{Lesher99effectsof} show that the performance has been seen to rely on training text size. It is mentioned in the report that the performance of a word predictor could be improved with syntax-based prediction which should be investigated. This is also mentioned by Keith Trnka et.al.\cite{keystrokes} that syntactic knowledge can help improve word prediction.
 
One goal of word predictors is to be able to give accurate results to sentences in different contexts \cite{DBLP:journals/corr/cs-CL-0009027}. This requires a way for the word predictor to recognize the context in the sentence.
 
Both syntax-based prediction (grammatical analysis) and context recognition require to be implemented along with a model. This work uses N-gram modelling since it is a common tool in NLP \cite{Wandmacher}. A problem with N-gram moddeling is that it uses training data which makes it possible that not all combinations of words occur, which requires a smoothing technique to give unseen N-grams some probability \cite{Russel}. Smoothing techniques are a requirement for word prediction to be usable for different sentences than those in the training data.
 
Combining  these techniques together: smoothing, grammatical rules and context recognition, is the problem this report focuses on, and how they can improve a word predictors' performance.

\subsection{Hypothesis}
In this section the hypothesis for this work is explained in the different categories: Smoothing techniques, grammatical constraints and context recognition.
\subsubsection{Smoothing techniques}
The smoothing techniques evaluated are kneser-ney smoothing and absolute discount smoothing. Both these smoothing techniques rely on similar ideas. They use a constant discount value to distribute probability from known N-grams to unknown N-grams. This idea can be seen from Good-Turing smoothing where the discounted value follow a similar pattern with a near constant discount \cite{coursera}.

Both the smoothing techniques interpolate their value from their lower N-grams but with different approaches. Absolute discounting uses the probability of the unigrams to interpolate the probability of a word, while Kneser-ney instead uses the continuation count of the word \cite{coursera}.

Our hypothesis regarding how the different smoothing techniques will perform in comparison to each other is that for a well-balanced corpus, they may provide similar predictions to each other. For instance for predicting the word after “it was”, the most popular words that follow this sentence can already be used in many different contexts and have a high unigram probability. If on the other hand the corpus is unbalanced and there is an unusual word which is overrepresented, it may have a high unigram probability. In absolute discounting this will give the unusual word a high prediction as an unseen word. For kneser-ney on the other hand it will still pick the words that are usable in many different contexts.

So for a balanced corpus, they may be quite similar, while with an unbalanced corpus Kneser-ney will provide better results.
\subsubsection{Grammatical constraints}
Grammatical constraints tries to apply the grammatical rules in a language to help the predictor to get more reasonable results. Our hypothesis is that these constraints will help in many cases to remove words that is unusable in a certain sentence. Since they can look on the complete sentence regardless of the N-gram sizes, they may provide valuable information on which N-grams that are usable in that current sentence. So the result using grammatical constraints should be better than without it.
\subsubsection{Context recognition}
By context recognition, it is meant that the word predictor tries to understand the context that a sentence is about and will try to provide suggestions based on that context. Context recognition may be both good and bad. If the context is misinterpreted the suggestions may be worse than without context recognition. Example of sentences which can be hard to understand the context in:

\begin{itemize}
\item My dog and I went to the beach and it was happy
\item My dog and I went to the beach and it was nice
\end{itemize}
These sentences are almost exactly the same but talk about different things. The first sentence talk about the dog, while the second sentence more talk about the experience.
Since the English language is a Subject-verb-object language, our hypothesis is that the probability to get the correct context should be higher than misinterpreting it.

\subsection{Contribution}
The results of this work could guide anyone who wants to implement a good word predictor. It may also be used to draw conclusions regarding questions that are not the main focus of this work. An example of such questions are ''when does a word predictor have to be efficient?''. Functionality that is bad in theory because it should perform very badly for some situations may prove practically good in a statistical research. Another question is ''what functionality is worth implementing?''. Some functionality may provide minimal improvement while being extremely resource hungry. Hopefully, this report will contribute to the field by providing results and discussions that could help give answers such questions.

\subsection{Outline}

This report is divided in several sections covering different part of the project. 
In part {REF till 2 related work} the material regarding findings and reaches  related to the current work made are brought up. This will also explain the basis which the project is founded on.   

In part {REF till 3 method}, the implementation of the word predictor is presented. Further the evaluation method  on how to measure the performance  of the implementation is explained. At last the important terms as part-of-speech-tagging, N-grams, context and grammatical features are also explained further into detail. 

In part {REF till 4 Results and analysis} the tests are explained further, the results presented and analysed.

In part {REF till 5 Discussion} the project as a whole is discussed. What could have been done different and what could be worked on further.

In pat {REF till 6 Summary} the report is wrapped up and summarized.

In this part {REF till 7 Contribution} all the members of the group states that the individual contribution have been equally distributed for this project.

In part {REF till References} the material referred in this work are listed.

In part {REF till resources} the tools used for implementation in this work are listed. 
