\section{Related work}

This work is most similar to Trnka, Yarrington, McCoy, and Pennington's study \cite{keystrokes} on keystroke savings. The objective of their study was different, but the methods used were well suited to test this work's hypotheses. A problem with the study was that it was focused on obtaining results that are very close to reality. In this work, we are interested in showing the effect of different functionalities of word predictors, thus making experiments that ought to increase the contrast in the results.

The methods used in the previously discussed work used N-gram models to predict words. WÃ¶ffel and McDonough's book ''Distant Speech Recognition'' \cite{search} as well as Hiemstra's ''Probability Smoothing'' \cite{smoothing} were used to get an in-depth understanding of Markov chains and smoothing used in constructing these models in the implementation of a word predictor.

Lastly, ''Corpus Studies in Word Prediction'' by Trnka and McFoy \cite{corpus} was helpful in understanding the effects training data, e.g. the corpus, may have in practice and how a corpus could be generated to produce good results. As for the firstly mentioned study, the results were heavily reality-oriented, why they could be expected to smooth out some differences in the results of this work.